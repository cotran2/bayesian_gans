{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters():\n",
    "    epochs = 10000\n",
    "    dataset = '2'\n",
    "    batch_size = 100\n",
    "    noise_size = 2\n",
    "    seed = 1234\n",
    "    n_samples = 1000\n",
    "    sampling_size = 500\n",
    "    # train/ not train\n",
    "    training_status = 'train'\n",
    "    # save/ load\n",
    "    data_status = 'save'\n",
    "    # write/ not\n",
    "    writing_status = 'not'\n",
    "params = HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16016     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 16,089\n",
      "Trainable params: 16,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                32032     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              5000      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 500, 2, 1)         0         \n",
      "=================================================================\n",
      "Total params: 37,836\n",
      "Trainable params: 37,732\n",
      "Non-trainable params: 104\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'y_train_2.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0493c4803106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0493c4803106>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, save_interval)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_train_{}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Rescale -1 to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cotran/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'y_train_2.npy'"
     ]
    }
   ],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 500\n",
    "        self.img_cols = 2\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        gen_optimizer = Adam(0.01, 0.5)\n",
    "        dis_optimizer = Adam(0.0002, 0.5)\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=dis_optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(1000,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=gen_optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (1000,)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(32, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(16))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(4))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(16))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(4))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "        params = HyperParameters()\n",
    "        # Load the dataset\n",
    "        X_train = np.load('y_train_{}.npy'.format(params.dataset))\n",
    "        # Rescale -1 to 1\n",
    "\n",
    "        half_batch = int(params.batch_size / 2)\n",
    "\n",
    "        for epoch in range(params.epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "#             noise = np.random.multivariate_normal(mean=[0,0],cov=np.eye(2),size=(half_batch,params.sampling_size))\n",
    "#             noise = np.reshape(noise,(half_batch,params.sampling_size*2))\n",
    "            noise = np.random.uniform(0,1,size = (half_batch,params.sampling_size*2))\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "#             noise = np.random.multivariate_normal(mean=[0,0],cov=np.eye(2),size=(params.batch_size,params.sampling_size))\n",
    "#             noise = np.reshape(noise,(params.batch_size,params.sampling_size*2))\n",
    "            noise = np.random.uniform(0,1,size = (params.batch_size,params.sampling_size*2))\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * params.batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % 100 == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        noise = np.random.multivariate_normal(mean=[0,0],cov=np.eye(2),size=(params.batch_size,params.sampling_size))\n",
    "        noise = np.reshape(noise,(params.batch_size,params.sampling_size*2))\n",
    "        print(noise.shape)\n",
    "        noise = np.random.uniform(0,1,size = (params.batch_size,params.sampling_size*2))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        gen_imgs = np.reshape(gen_imgs[0],(params.sampling_size,2))\n",
    "        \n",
    "        # Rescale images 0 - 1\n",
    "\n",
    "        plt.scatter(gen_imgs[:,0], gen_imgs[:,1], c='red', alpha=0.5)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.xlim([-5, 5])\n",
    "        plt.ylim([-5, 5])\n",
    "        plt.show()\n",
    "        if not os.path.exists(\"/imgs\"):\n",
    "            os.makedirs(\"/imgs\")\n",
    "        plt.savefig(\"/imgs/%d.png\".format(epoch), dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=30000, batch_size=32, save_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.load('x_train_{}.npy'.format(params.dataset))\n",
    "X_train = np.load('y_train_{}.npy'.format(params.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(samples[2],(500,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train[:,0], X_train[:,1], c='red', alpha=0.5)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlim([-5, 5])\n",
    "plt.ylim([-5, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
